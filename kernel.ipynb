{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport ast\nfrom glob import glob\n\nimport gc\n\n%matplotlib inline\n%config InlineBackend.figure_format = 'retina'\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\ntrain_files = glob(\"../input/train_simplified/*.csv\")\n\n# Any results you write to the current directory are saved as output.",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "98aed7cfb7d1a1c3e6e4448997d6f2d0961f1521"
      },
      "cell_type": "code",
      "source": "# Configuration for data\n\n# Width/Height (images are squares) of each image\nIMAGE_SIZE = 32\n\n# Total number of classes of the given problem \nNUM_CLASSES = 340\n\n# Total number of instances used for train or validation tests\nNUM_ROWS_TOTAL = 49707919//96\nNUM_ROWS_TOTAL -= (NUM_ROWS_TOTAL % NUM_CLASSES)\n\n# How many lines of the input file must be readed, at a maximum, each iteration\nCHUNKSIZE = 1024\n\n# Number of instances of each class\nEACH_SET_SIZE = NUM_ROWS_TOTAL // NUM_CLASSES\n\nprint(\"total instances:\", NUM_ROWS_TOTAL)\nprint(\"images per class:\", EACH_SET_SIZE)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "292fd37f5b57508b2719d15406ad1775c8e2fec9"
      },
      "cell_type": "code",
      "source": "from PIL import Image, ImageDraw\nfrom dask import bag\n\n# Rasterizarion algorithm from https://www.kaggle.com/jpmiller/image-based-cnn#\ndef draw_it(strokes, imheight=32, imwidth=32):\n    image = Image.new(\"P\", (256,256), color=255)\n    image_draw = ImageDraw.Draw(image)\n    for stroke in ast.literal_eval(strokes):\n        for i in range(len(stroke[0])-1):\n            image_draw.line([stroke[0][i], \n                             stroke[1][i],\n                             stroke[0][i+1], \n                             stroke[1][i+1]],\n                            fill=0, width=5)\n    image = image.resize((imheight, imwidth))\n    return np.array(image)/255.",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6ba506df4484a08f1840b7a4a12a0bba8f000b98",
        "scrolled": true
      },
      "cell_type": "code",
      "source": "# Allocate heavy RAM memory for all train data images & classes at one shot\n# in order to speed up the processing\nraster_array = np.zeros((NUM_ROWS_TOTAL, IMAGE_SIZE, IMAGE_SIZE, 1))\nclasses = pd.Series([None] * NUM_ROWS_TOTAL)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "19190665b05a5ca3e9bc9f367d29bb289d52fa3d"
      },
      "cell_type": "code",
      "source": "# Reading and rasterizing on-demand, to save memory\ni = 0\nfor f in train_files:\n    for df in pd.read_csv(f, index_col=\"key_id\", chunksize=CHUNKSIZE, nrows=EACH_SET_SIZE):\n        imagebag = bag.from_sequence(df.drawing.values).map(draw_it, imheight=IMAGE_SIZE, imwidth=IMAGE_SIZE)\n        imagebag = np.array(imagebag.compute())\n        classes[i:(i + imagebag.shape[0])] = df[\"word\"].replace(\"\\s+\", \"_\", regex=True)\n        raster_array[i:(i + imagebag.shape[0])] = imagebag.reshape((*imagebag.shape, 1))\n        i += imagebag.shape[0]\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0f0112ce8754ec4a2b487ad2df82bcf04aab9165"
      },
      "cell_type": "code",
      "source": "# Shuffle raster_array and classes in unison\nimport numpy.core.defchararray as np_f\n\ndef shuffle_in_unison(a, b):\n    rng_state = np.random.get_state()\n    np.random.shuffle(a)\n    np.random.set_state(rng_state)\n    np.random.shuffle(b)\n\nclasses = classes.values\nshuffle_in_unison(raster_array, classes)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2994e2226eae2f7dd9cca9c1bd9a11c7ffcdcaea"
      },
      "cell_type": "code",
      "source": "# Get class dummies\ndummies = pd.get_dummies(classes)\ndummies.head(n=10)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "86f2e078a5ca9e6d09ad1639b15f20697503f655",
        "_kg_hide-output": true,
        "_kg_hide-input": true
      },
      "cell_type": "code",
      "source": "# Print rasterized images\nplt.figure(figsize=(16, 16))\nfor index, image in enumerate(raster_array[:100]):\n    plt.subplot(10, 10, index+1)\n    plt.gca().invert_yaxis()\n    plt.axis(\"off\")\n    plt.imshow(image.reshape((IMAGE_SIZE, IMAGE_SIZE)), cmap=\"binary\")\n\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "202dee57861dc49e43105aa3000212d518d3d85b"
      },
      "cell_type": "code",
      "source": "# Split training data for validation\nfrom sklearn.model_selection import train_test_split\ntrain_X,valid_X,train_label,valid_label = train_test_split(raster_array, dummies, test_size=0.2, random_state=13)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0b74bf366479ba17ba8e6d12c4f3dc7d047c7516"
      },
      "cell_type": "code",
      "source": "train_X.shape,valid_X.shape,train_label.shape,valid_label.shape",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1c2a58ffce7baeb3ab9e085ea7839239119d7560"
      },
      "cell_type": "code",
      "source": "# Remove raster_array to free up RAM memory\ndel raster_array\ngc.collect()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d84218dbd83f23af14828fe35f5c2d2b9c8d8259"
      },
      "cell_type": "code",
      "source": "# Constants\nBATCH_SIZE = 1024\nEPOCHS = 40\nNUM_CLASSES = 340\nSHAPE = (IMAGE_SIZE, IMAGE_SIZE, 1)\nFILTER_SIZE = (4, 4)\nPROB_DO_HIDDEN = 0.3",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4338e7578cf0fbeda4016b8a758ba91ba6802116"
      },
      "cell_type": "code",
      "source": "# CNN Architecture \nimport keras\nfrom keras.models import Sequential,Input,Model\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers.advanced_activations import LeakyReLU\nfrom keras.layers import Activation\n\nmodel = Sequential()\nmodel.add(Conv2D(32, kernel_size=FILTER_SIZE, strides=1, input_shape=SHAPE))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(PROB_DO_HIDDEN))\n\nmodel.add(Conv2D(64, kernel_size=FILTER_SIZE, strides=1))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(PROB_DO_HIDDEN))\n\nmodel.add(Flatten())\nmodel.add(Dense(1024))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(PROB_DO_HIDDEN))\n\nmodel.add(Dense(NUM_CLASSES))\nmodel.add(Activation('softmax'))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9a713d4727742c3ec89cedba13b137111d5cb65c"
      },
      "cell_type": "code",
      "source": "# Fonte: https://stackoverflow.com/questions/42327006/how-to-calculate-top5-accuracy-in-keras\nimport functools\ntop3_acc = functools.partial(keras.metrics.top_k_categorical_accuracy, k=3)\n\ntop3_acc.__name__ = 'top3_acc'",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a3b7b43d0f23735a46c1f91828d7d4d2a663fa21"
      },
      "cell_type": "code",
      "source": "model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adam(), metrics=['accuracy', top3_acc])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "33d0aec247a4f4833d0101e44052cf997b3ae183"
      },
      "cell_type": "code",
      "source": "model.summary()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4fb74b7c4fe51d44a36cd80fa3514f4cd30ba3ab"
      },
      "cell_type": "code",
      "source": "from keras.callbacks import EarlyStopping\nearly_stopping_monitor = EarlyStopping(patience=int(EPOCHS*0.15))\n\nhistory = model.fit(train_X, train_label, batch_size=BATCH_SIZE,epochs=EPOCHS,verbose=1,validation_data=(valid_X, valid_label), callbacks=[early_stopping_monitor])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "240cda22226670911049ed4fea322fff306e7f01"
      },
      "cell_type": "code",
      "source": "# Plot training & validation accuracy values\nplt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()\n\n# Plot training & validation accuracy values\nplt.plot(history.history['top3_acc'])\nplt.plot(history.history['val_top3_acc'])\nplt.title('Model accuracy (top 3)')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()\n\n# Plot training & validation loss values\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4a9d3f865954c5a3b492c4415a5fd04d05b68902"
      },
      "cell_type": "code",
      "source": "# Free train/validation memory up\ndel train_X, valid_X, train_label, valid_label\ngc.collect()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b06b33cb5ea4c69bd56bb82c6647b6605d57b876"
      },
      "cell_type": "code",
      "source": "# Reading test file\ntest = pd.read_csv('../input/test_simplified.csv', index_col=\"key_id\")\ntest.head()\ntestidx = test.index",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6ca2d5532ffd7f1419c0ef7d8e6e4ea76383390a"
      },
      "cell_type": "code",
      "source": "# Rasterizing vector images of test set\nimagebag = bag.from_sequence(test.drawing.values).map(draw_it, \n                                                      imheight=IMAGE_SIZE, \n                                                      imwidth=IMAGE_SIZE)\n\ntest_X = np.array(imagebag.compute())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5ea5b4d5f1edfec0049b7f89b5beeef45bb9032f"
      },
      "cell_type": "code",
      "source": "# Reshape test set\ntest_X = test_X.reshape(-1, IMAGE_SIZE, IMAGE_SIZE, 1)\ntest_X.shape",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7a6f1b6e632e57ebaf80c9b177cccc136bdded07"
      },
      "cell_type": "code",
      "source": "# Predict test dataset with model\ntest_Y = model.predict(test_X, batch_size=BATCH_SIZE)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ebe64cc4b4e1b0d376b8bccc898fbbd2677ac048"
      },
      "cell_type": "code",
      "source": "# Get top 3 classes\nans = np.argsort(-test_Y)[:,:3]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "96849028a84b369ece6146b525b4cc5b744f3a27"
      },
      "cell_type": "code",
      "source": "ans",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2c19c22c555a9e895228ba749b470080e70ea09e"
      },
      "cell_type": "code",
      "source": "# Generating output\nout_aux = []\nfor id, i in zip(testidx, dummies.columns[ans]):\n    out_aux.append([id, \" \".join(map(str, i))])\n\noutput = pd.DataFrame(columns=['key_id', 'word'], data=out_aux)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0a228b2123b823bd25e1809c39802923ca6b5001"
      },
      "cell_type": "code",
      "source": "output.head(n=10)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c74b12ecd24d69d3e3d955b89204121af5fce15c"
      },
      "cell_type": "code",
      "source": "output.to_csv(\"submission.csv\", index=False)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d84e8d67b78061119b581f395add5df42798af44"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}